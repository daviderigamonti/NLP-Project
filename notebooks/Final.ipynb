{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ce1016-35e5-49cf-8c91-170b46d7b7df",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project\n",
    "## NLP Course @ Politecnico di Milano 2022/2023 - Prof. Mark Carman\n",
    "### Topic 4: Autextification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827eff8a-355b-4bcc-ab68-c039bc6aa153",
   "metadata": {},
   "source": [
    "### Group: Residual Sum of Students\n",
    "- Raul Singh\n",
    "- Davide Rigamonti\n",
    "- Francesco Tosini\n",
    "- Enrico Zuccolotto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41621b4b-6956-4014-9154-f1e0b03f451d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The dataset consists of *short text passages* that have either been written by a *human* or have been generated automatically by a *language model*, more information can be found on the [official site](https://sites.google.com/view/autextification).\n",
    "\n",
    "The original task will take place as part of [IberLEF 2023](http://sepln2023.sepln.org/en/iberlef-en/), the 5th Workshop on Iberian Languages Evaluation Forum at the SEPLN 2023 Conference, which will be held in Ja√©n, Spain on the 26th of September, 2023.\n",
    "\n",
    "Given the scope of the original challenge we can observe that the dataset contains two separate set of samples, one in **English** and the other in **Spanish**; our main focus will be on the **English** dataset.\n",
    "\n",
    "We will treat the two tasks **separately** as the two respective goals are different; although some similarities can be traced between the two, most of the considered approaches will be symmetrical and net homogeneous results.\n",
    "\n",
    "Each task will be presented with a brief **data exploration** section, then we will proceed to utilize models and approaches that we have seen in the course (with the introduction of some novelties) starting from the most basic techniques based on the **Bag of Words representation** to then transition towards approaches that utilize **Word Embeddings** to then reach the *state-of-the-art* **Transformer** models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1402c1-9723-4b39-bad1-2160c5570b37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preliminary initialization\n",
    "\n",
    "This section contains all the library imports, helper function initialization calls and global variable definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8540e8-6fa0-4e62-9830-240ddd80e116",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5965d0-a5b6-4d67-8500-dd24f8f5a1c8",
   "metadata": {},
   "source": [
    "#### Utilized libraries\n",
    "The following dependencies are needed to run the notebook:\n",
    "```\n",
    "pip install scikit-learn~=1.2.2\n",
    "pip install torch~=2.0.0\n",
    "pip install matplotlib~=3.7.1\n",
    "pip install plotly~=5.14.1\n",
    "pip install nltk~=3.8.1\n",
    "pip install spacy~=3.5.1\n",
    "pip install textstat~=0.7.3\n",
    "pip install numpy~=1.24.2\n",
    "pip install pandas~=2.0.0\n",
    "pip install python-terrier~=0.9.2\n",
    "pip install scipy~=1.9.3\n",
    "pip install gensim~=4.3.1\n",
    "pip install lexicalrichness~=0.5.0\n",
    "pip install sentence-transformers~=2.2.2\n",
    "pip install transformers~=4.28.1\n",
    "pip install datasets~=2.12.0\n",
    "pip install evaluate~=0.4.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b9f32d-8503-4529-b166-7026fe5f00fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Python standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67862620-d6cb-49a8-a43d-9c757dc155f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import abc\n",
    "import random\n",
    "import string\n",
    "\n",
    "import copy as cp\n",
    "import array as arr\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017ffba-d718-4b78-8878-c63baba7f9e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919f457-f9ff-4d0f-a263-b3eb294d0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707ec75-d9b5-4944-b880-011889575e54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535df294-54e2-43e0-8459-0325d09ca0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.utils.data as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efb1d4-703b-43ab-afad-62748a60a6bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b2a8a-b96d-4601-900a-da2ce73b0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a50a7-cfdf-4ddc-b2c5-d4becf39a265",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Various"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4379d06-db1d-4d31-8eee-7686828d9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import textstat\n",
    "\n",
    "import evaluate as hf_ev\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import scipy.sparse as sps\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "from spacy import displacy\n",
    "from nltk.corpus import stopwords\n",
    "from pandas.core.common import flatten\n",
    "from datasets import Dataset, DatasetDict\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from lexicalrichness import LexicalRichness\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from nlp_project.notebook_utils import compact_split, evaluate\n",
    "\n",
    "from nlp_project.notebook_utils import evaluate, split, save_scikit_model, load_scikit_model\n",
    "from nlp_project.nn_utils import init_gpu\n",
    "from nlp_project.nn_classifier import Data, Classifier\n",
    "from nlp_project.nn_extra import EarlyStopping, AdaptLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486853e-d211-40dc-82cc-ba64f404b5e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0678743-04c3-4acc-b4fe-0cb6f9b6c62c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47a7b1-c31f-4a5b-9b1a-998781e6e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_metrics = {\n",
    "    \"epoch\": {},\n",
    "    \"loss\": {\"order\": -1},\n",
    "    \"val_loss\": {\"order\": -1},\n",
    "    \"acc\": {\"order\": +1},\n",
    "    \"val_acc\": {\"order\": +1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d625bf-0226-4a92-a225-1245fc677544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopNNLoop(BaseException):\n",
    "    pass\n",
    "\n",
    "def build_history_string(history_point):\n",
    "    epoch = history_point[\"epoch\"]\n",
    "    metrics_string = \" \".join(\n",
    "        [f\"{k}: {history_point[k]:.7f}\" for k in history_point if not k == \"epoch\"]\n",
    "    )\n",
    "    return f\"Epoch {epoch} -- \" + metrics_string\n",
    "\n",
    "\n",
    "def compare_equal_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(\n",
    "        model_1.state_dict().items(), model_2.state_dict().items()\n",
    "    ):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if key_item_1[0] == key_item_2[0]:\n",
    "                print(\"Mismtach found at\", key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Returns true if a is \"better\" than b following the metric\n",
    "def compare_metric(metric, a, b, delta=0):\n",
    "    if a == b:\n",
    "        return False\n",
    "    if history_metrics[metric][\"order\"] == +1:\n",
    "        return a > b + delta\n",
    "    return a < b - delta\n",
    "\n",
    "\n",
    "# Initializes lowest possible value given a metric\n",
    "def init_lowest(metric):\n",
    "    return -np.inf if history_metrics[metric][\"order\"] == +1 else np.inf\n",
    "\n",
    "\n",
    "def init_gpu(gpu=\"cuda:0\"):\n",
    "    return torch.device(gpu if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b3d28-573b-49e4-849a-85d76b1e30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(dt.Dataset):\n",
    "    def __init__(self, x, y, x_type=np.int32, y_type=torch.float):\n",
    "        x_coo = x.tocoo()\n",
    "        self.x = torch.sparse.FloatTensor(\n",
    "            torch.LongTensor([x_coo.row, x_coo.col]),\n",
    "            torch.FloatTensor(x_coo.data.astype(x_type)),\n",
    "            x_coo.shape,\n",
    "        )\n",
    "        self.y = torch.tensor(y, dtype=y_type)\n",
    "        self.shape = self.x.shape\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index].to_dense(), self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162e0b5-7b9d-444e-a5c4-1a584bdd1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, binary_classifier=False, device=torch.device(\"cpu\"), verbose=True):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.is_binary = binary_classifier\n",
    "        self.verbose = verbose\n",
    "        self.is_compiled = False\n",
    "        self.history = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    def compile(self, loss, optimizer, binary_threshold=0.5):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.binary_threshold = binary_threshold\n",
    "        self.to(self.device)\n",
    "        self.is_compiled = True\n",
    "\n",
    "    def parse_logits(self, outputs):\n",
    "        if self.is_binary:\n",
    "            predicted = (outputs > self.binary_threshold).float()\n",
    "        else:\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted\n",
    "\n",
    "    def train_loop(self, data, epochs, data_val=None, callbacks=[]):\n",
    "        try:\n",
    "            tot = len(data.dataset)\n",
    "            # Iterate over all epochs\n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                history_point = {}\n",
    "                # Iterate over each dataset batch\n",
    "                for i, datum in enumerate(data):\n",
    "                    # Decompose batch in x and y\n",
    "                    inputs, labels = datum\n",
    "                    # Set gradients to zero\n",
    "                    self.optimizer.zero_grad()\n",
    "                    # Forward pass\n",
    "                    outputs = self(inputs)\n",
    "                    predictions = self.parse_logits(outputs)\n",
    "                    current_loss = self.loss(outputs, labels)\n",
    "                    # Backpropagation\n",
    "                    current_loss.backward()\n",
    "                    # Optimization\n",
    "                    self.optimizer.step()\n",
    "                    # Update metrics\n",
    "                    running_loss += current_loss.item()\n",
    "                    correct += (predictions == labels).float().sum()\n",
    "\n",
    "                # Compute training metrics\n",
    "                history_point[\"epoch\"] = epoch + 1\n",
    "                history_point[\"loss\"] = running_loss / tot\n",
    "                history_point[\"acc\"] = correct / tot\n",
    "\n",
    "                # Compute and save eventual validation metrics\n",
    "                if data_val:\n",
    "                    _, val_metrics = self.test_loop(data_val)\n",
    "                    history_point[\"val_loss\"] = val_metrics[\"loss\"]\n",
    "                    history_point[\"val_acc\"] = val_metrics[\"acc\"]\n",
    "\n",
    "                # Save epoch in history\n",
    "                self.history.append(history_point)\n",
    "\n",
    "                # Perform callbacks\n",
    "                for callback in callbacks:\n",
    "                    callback.call(self, history_point)\n",
    "\n",
    "                # Print epoch summary\n",
    "                if self.verbose:\n",
    "                    print(build_history_string(history_point))\n",
    "\n",
    "        except StopNNLoop as s:  # noqa\n",
    "            pass\n",
    "\n",
    "    def test_loop(self, data):\n",
    "        all_predictions = np.array([])\n",
    "        tot = len(data.dataset)\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        metrics = {}\n",
    "        # Prevent model update\n",
    "        with torch.no_grad():\n",
    "            # Iterate over each dataset batch\n",
    "            for datum in data:\n",
    "                # Decompose batch in x and y\n",
    "                inputs, labels = datum\n",
    "                # Forward pass\n",
    "                outputs = self(inputs)\n",
    "                predictions = self.parse_logits(outputs)\n",
    "                current_loss = self.loss(outputs, labels)\n",
    "                # Update metrics\n",
    "                loss += current_loss.item()\n",
    "                correct += (predictions == labels).float().sum()\n",
    "                # Append predictions\n",
    "                all_predictions = np.append(all_predictions, predictions)\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics[\"acc\"] = correct / tot\n",
    "        metrics[\"loss\"] = loss / tot\n",
    "\n",
    "        return all_predictions.flatten(), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e6161-bbe1-452b-8777-151b7eb45ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(metaclass=abc.ABCMeta):\n",
    "    def __init__(self, inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            raise TypeError(\"Parameter 'inputs' must be a list\")\n",
    "        if not all(x in history_metrics for x in inputs):\n",
    "            raise ValueError(\n",
    "                \"Unknown input value, not present in Callback.callback_inputs\"\n",
    "            )\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def inputs_check(self, inputs):\n",
    "        if not all(x in inputs for x in self.inputs):\n",
    "            raise ValueError(\n",
    "                f\"Requested inputs not provided: {[i for i in inputs if i not in self.inputs]}\"\n",
    "            )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def call(self, model, inputs):\n",
    "        self.inputs_check(inputs)\n",
    "        pass\n",
    "\n",
    "class EarlyStopping(Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        metric=\"loss\",\n",
    "        patience=10,\n",
    "        baseline=None,\n",
    "        delta=0,\n",
    "        restore_best=True,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        super().__init__([metric])\n",
    "        self.metric = metric\n",
    "        self.patience = patience\n",
    "        self.baseline = baseline\n",
    "        self.delta = delta\n",
    "        self.restore_best = restore_best\n",
    "        self.verbose = verbose\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.saved_params = {}\n",
    "        self.last_best = init_lowest(self.metric)\n",
    "\n",
    "    def call(self, model, inputs):\n",
    "        super().call(model, inputs)\n",
    "        if self.early_stop(model, inputs):\n",
    "            raise StopNNLoop()\n",
    "\n",
    "    def early_stop(self, model, inputs):\n",
    "        metric = inputs[self.metric]\n",
    "        # Check if new metric is better than the current best\n",
    "        if compare_metric(self.metric, metric, self.last_best):\n",
    "            # Reset counter and update best value\n",
    "            self.last_best = metric\n",
    "            self.counter = 0\n",
    "            self.best_epoch = inputs[\"epoch\"]\n",
    "            # Update model checkpoint\n",
    "            if compare_metric(self.metric, metric, self.baseline):\n",
    "                self.saved_params = cp.deepcopy(model.state_dict())\n",
    "        # Check if new metric is worse than the current best\n",
    "        elif compare_metric(self.metric, self.last_best, metric, self.delta):\n",
    "            # Increment counter\n",
    "            self.counter += 1\n",
    "            # Check if counter exceeds patience, if so interrupt training\n",
    "            if self.counter >= self.patience:\n",
    "                # Restore best model checkpoint if possible and wanted\n",
    "                if not self.restore_best:\n",
    "                    return True\n",
    "                if self.saved_params:\n",
    "                    model.load_state_dict(self.saved_params)\n",
    "                if self.verbose:\n",
    "                    if self.saved_params:\n",
    "                        print(f\"Model restored successfully @ epoch {self.best_epoch}\")\n",
    "                    else:\n",
    "                        print(f\"Couldn't restore model @ epoch {self.best_epoch}\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class AdaptLR(Callback):\n",
    "    def __init__(self, metric=\"loss\", patience=5, factor=0.1, delta=0, verbose=True):\n",
    "        super().__init__([metric])\n",
    "        self.metric = metric\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.last_best = init_lowest(self.metric)\n",
    "\n",
    "    def call(self, model, inputs):\n",
    "        super().call(model, inputs)\n",
    "        if self.adaptlr(inputs):\n",
    "            # Adapt learning rate\n",
    "            out = []\n",
    "            for g in model.optimizer.param_groups:\n",
    "                g[\"lr\"] *= self.factor\n",
    "                out = g[\"lr\"]\n",
    "            if self.verbose:\n",
    "                print(f\"Reducing lr to {out:.4f}\")\n",
    "\n",
    "    def adaptlr(self, inputs):\n",
    "        metric = inputs[self.metric]\n",
    "        # Check if new metric is better than the current best\n",
    "        if compare_metric(self.metric, metric, self.last_best):\n",
    "            # Reset counter and update best value\n",
    "            self.last_best = metric\n",
    "            self.counter = 0\n",
    "        # Check if new metric is worse than the current best\n",
    "        elif compare_metric(self.metric, self.last_best, metric, self.delta):\n",
    "            # Increment counter\n",
    "            self.counter += 1\n",
    "            # Check if counter exceeds patience, if so interrupt training\n",
    "            if self.counter >= self.patience:\n",
    "                self.counter = 0\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace11272-c716-42c3-8d42-6e242fde071f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Generic utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077b9ea-3354-4fa4-b7e0-caeba1d0d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x, y, test_size=0.2, val_size=0.0, seed=0):\n",
    "    if val_size + test_size >= 1:\n",
    "        return None\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size + val_size, stratify=y, random_state=seed\n",
    "    )\n",
    "    x_val, y_val = None, None\n",
    "    if val_size > 0:\n",
    "        x_test, x_val, y_test, y_val = train_test_split(\n",
    "            x_test,\n",
    "            y_test,\n",
    "            test_size=val_size / (test_size + val_size),\n",
    "            stratify=y_test,\n",
    "            random_state=seed,\n",
    "        )\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "def compact_split(dataset, test_size=0.2, val_size=0.0, seed=0):\n",
    "    if val_size + test_size >= 1:\n",
    "        return None\n",
    "    train, test = train_test_split(\n",
    "        dataset, test_size=test_size + val_size, random_state=seed\n",
    "    )\n",
    "    val = None\n",
    "    if val_size > 0:\n",
    "        val, test = train_test_split(\n",
    "            test,\n",
    "            test_size=test_size / (test_size + val_size),\n",
    "            random_state=seed,\n",
    "        )\n",
    "    return train, val, test\n",
    "\n",
    "def evaluate(y_true, y_pred, labels=None):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "\n",
    "def save_scikit_model(path, model, name):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    dump(model, path + \"/\" + name)\n",
    "\n",
    "def load_scikit_model(path, name):\n",
    "    model_path = path + \"/\" + name\n",
    "    if exists(model_path) and isfile(model_path):\n",
    "        try:\n",
    "            return load(model_path)\n",
    "        except:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675eea3-5d1b-44c1-a83e-9cdcdfa8c92b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375ffce-e431-49fd-909d-916b60cdefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c24b6-3c8f-409a-ac32-385bf28313f9",
   "metadata": {},
   "source": [
    "#### Library initialization calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81524a-b7b3-4d23-8da6-f2b1236f6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load spacy pipeline model\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00998b82-302e-4c79-9c0b-c911f30753cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 1\n",
    "\n",
    "The challange is subdivided in two main tasks, the first is a **Binary Classification** task that aims at identifying if a text passage was *written by a human* or if it was *generated from a langauge model*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef8164-1de1-4afd-98cd-f050a1335924",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0fd22-f7c4-4cc7-94a1-56e288c9454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311aefcc-aa9d-4bf4-b1ac-4e2ff099d6d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bag of Words-based models and other approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8f243-e2d8-4bfd-9cbc-5689229a8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91aa2c-d936-4188-b61e-fa12789d4918",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Text embedding approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb977bc-92e5-4e7e-9743-36bc5abc6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed5d4f-7f7e-4302-a80e-89cb06d2cead",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transformer-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7dd276-4653-4a2f-9040-3dd856ab08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a167d75-a0f6-429f-8308-e859a068b9fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 2\n",
    "\n",
    "The challange is subdivided in two main tasks, the second task is a **Multinomial Classification** task that aims at identifying the specific *language model* that generated a given text passage, choosing from 6 different models labeled as A, B, C, D, E and F."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd205d9-bc58-4d98-97f6-a09601472f73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65458c-944d-463b-a7d9-6daef11b154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989117e8-6a2d-4eb2-99b3-73e44cd41277",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bag of Words-based models and other approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2f44-4f3c-4127-b5fb-df46b56ed0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcbed7-c47f-494a-9410-5a479962a312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Text embedding approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c58057-ce5a-472d-b906-be76f5deae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60977ce7-7d35-43f7-8cfb-f282af480df4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transformer-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345c040-bac1-4a35-a276-30adfc430e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57059c84-45b4-432c-affc-9c18ecddadb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ff298-77a6-4ebf-8b3e-75b0df5ad52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
