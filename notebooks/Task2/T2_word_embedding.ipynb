{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXO7XgilmgeN"
   },
   "source": [
    "# Loading of the training set.\n",
    "\n",
    "We peek the datset using the function head() to see its composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NwYBfRy6lSSW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XQ-Mo1lZmgeO",
    "outputId": "9ce1bd29-f049-4170-d7c9-05ec01fdc676",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12322</td>\n",
       "      <td>you need to stop the engine and wait until it stops. This is how I would do it: // Check if its safe</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1682</td>\n",
       "      <td>The Commission shall publish the report; an interim report at least once every two years, and whenever it considers that such a report is necessar...</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22592</td>\n",
       "      <td>I have not been tweeting a lot lately, but I did in November, and it was a really good month. I also</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17390</td>\n",
       "      <td>I pass my exam and really thankgod for that but idk where will I go for shsmy result is ah</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30453</td>\n",
       "      <td>The template will have 3 parts: a mustache shape, a bow tie shape, and a skinny rectangle. The mustache shape will eventually make the bow loops. ...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   \n",
       "0  12322  \\\n",
       "1   1682   \n",
       "2  22592   \n",
       "3  17390   \n",
       "4  30453   \n",
       "\n",
       "                                                                                                                                                    text   \n",
       "0                                                   you need to stop the engine and wait until it stops. This is how I would do it: // Check if its safe  \\\n",
       "1  The Commission shall publish the report; an interim report at least once every two years, and whenever it considers that such a report is necessar...   \n",
       "2                                                   I have not been tweeting a lot lately, but I did in November, and it was a really good month. I also   \n",
       "3                                                             I pass my exam and really thankgod for that but idk where will I go for shsmy result is ah   \n",
       "4  The template will have 3 parts: a mustache shape, a bow tie shape, and a skinny rectangle. The mustache shape will eventually make the bow loops. ...   \n",
       "\n",
       "       label  \n",
       "0  generated  \n",
       "1  generated  \n",
       "2  generated  \n",
       "3      human  \n",
       "4      human  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/zucco/OneDrive - Politecnico di Milano/Desktop/NLP_task/subtask_1/en/train.tsv.gz\",sep=\"\\t\",header=0)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRWa_IQlykDP"
   },
   "source": [
    "Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_zbFzm-4JmS"
   },
   "source": [
    "# Classifying with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-ELUm_BEmB5z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim import downloader as api\n",
    "import string\n",
    "import re\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from nlp_project.notebook_utils import evaluate, split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:04:51.622105Z",
     "iopub.status.busy": "2023-05-11T19:04:51.621446Z",
     "iopub.status.idle": "2023-05-11T19:04:51.664087Z",
     "shell.execute_reply": "2023-05-11T19:04:51.663274Z",
     "shell.execute_reply.started": "2023-05-11T19:04:51.622069Z"
    },
    "id": "KF2Efq9U4I9Q"
   },
   "outputs": [],
   "source": [
    "df.sample(frac=1)\n",
    "df['label'] = df['label'].replace({'A':0, 'B':1,'C':2,'D':3,'E':4,'F':5,})\n",
    "labels=['A','B','C','D','E','F']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:24.616204Z",
     "iopub.status.busy": "2023-05-11T19:05:24.615848Z",
     "iopub.status.idle": "2023-05-11T19:05:24.624898Z",
     "shell.execute_reply": "2023-05-11T19:05:24.623897Z",
     "shell.execute_reply.started": "2023-05-11T19:05:24.616175Z"
    },
    "id": "6EESZJ3Q484e"
   },
   "outputs": [],
   "source": [
    "\n",
    "regex = '[' + string.punctuation + ']'\n",
    "def vectorize(docs, embedding_model, useSum ,dim):\n",
    "    vectors = np.zeros((len(docs),dim))\n",
    "    for i in range(len(docs)):\n",
    "        tokens = re.sub(regex, '', docs[i].lower()).split()\n",
    "        embeddings = [embedding_model.get_vector(token) for token in tokens if token in embedding_model]\n",
    "        if (len(embeddings) > 0):\n",
    "            if (useSum): \n",
    "                vectors[i] = sum(embeddings)\n",
    "            else:\n",
    "                vectors[i] = np.mean(embeddings, axis=0)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:44.009620Z",
     "iopub.status.busy": "2023-05-11T19:05:44.009253Z",
     "iopub.status.idle": "2023-05-11T19:05:44.015581Z",
     "shell.execute_reply": "2023-05-11T19:05:44.014581Z",
     "shell.execute_reply.started": "2023-05-11T19:05:44.009590Z"
    },
    "id": "nyTiPh9b5SH5"
   },
   "outputs": [],
   "source": [
    "def prep_dataset(word_embeds,dim,useSum):\n",
    "    model = api.load(word_embeds)\n",
    "    x_train = vectorize(np.array(df['text']),model,useSum,dim)\n",
    "    y_train= np.array(df['label'])\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = split(x_train, y_train, test_size=0.2, val_size=0.0)\n",
    "    return model,x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:44.259396Z",
     "iopub.status.busy": "2023-05-11T19:05:44.258539Z",
     "iopub.status.idle": "2023-05-11T19:05:44.269254Z",
     "shell.execute_reply": "2023-05-11T19:05:44.268091Z",
     "shell.execute_reply.started": "2023-05-11T19:05:44.259362Z"
    }
   },
   "outputs": [],
   "source": [
    " def setup_models():   \n",
    "    models = []\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr_param = [{\n",
    "        \"solver\": [\"liblinear\"], \n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\":[0.01, 0.1, 1, 10]\n",
    "    },{\n",
    "        \"solver\": (\"lbfgs\", \"sag\", \"saga\"), \n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\":[0.01, 0.1, 1]\n",
    "    }]\n",
    "    lr_clf = GridSearchCV(lr, lr_param, cv=5, scoring=\"f1_micro\", verbose=1)\n",
    "    models.append({\"name\": \"Linear Regression\", \"model\": lr_clf})\n",
    "\n",
    "    # SVC\n",
    "    svc = SVC()\n",
    "    svc_param = {\"kernel\": [\"rbf\"], \"C\": [0.1, 1, 10]}\n",
    "    svc_clf = GridSearchCV(svc, svc_param, cv=5, scoring=\"f1_micro\", verbose=1)\n",
    "    models.append({\"name\": \"SVC\", \"model\": svc_clf, \"subsample\": 0.7})\n",
    "\n",
    "    # ExtraTreesClassifier\n",
    "    et = ExtraTreesClassifier()\n",
    "    et_param = {\"n_estimators\":[10, 50, 100, 200, 500, 1000]}\n",
    "    et_clf = GridSearchCV(et, et_param, cv=5, scoring=\"f1_micro\", verbose=1)\n",
    "    models.append({\"name\": \"ExtraTree\", \"model\": et_clf})\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:44.461584Z",
     "iopub.status.busy": "2023-05-11T19:05:44.461064Z",
     "iopub.status.idle": "2023-05-11T19:05:44.468622Z",
     "shell.execute_reply": "2023-05-11T19:05:44.467603Z",
     "shell.execute_reply.started": "2023-05-11T19:05:44.461549Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_models(models,x_train,y_train):    \n",
    "    for model in models:\n",
    "        print(f\"Training {model['name']}\")\n",
    "        x_train_, y_train_ = x_train, y_train\n",
    "        if \"subsample\" in model.keys():\n",
    "            x_train_, _, y_train_, _ = train_test_split(\n",
    "                x_train, \n",
    "                y_train, \n",
    "                test_size=model[\"subsample\"], \n",
    "                stratify=y_train\n",
    "            )\n",
    "        model[\"model\"].fit(x_train_, y_train_)\n",
    "        print(\"Found best model\")\n",
    "        model[\"best\"] = model[\"model\"].best_estimator_\n",
    "        model[\"best\"].fit(x_train, y_train)\n",
    "        print(\"Trained best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:44.641484Z",
     "iopub.status.busy": "2023-05-11T19:05:44.641211Z",
     "iopub.status.idle": "2023-05-11T19:05:44.646864Z",
     "shell.execute_reply": "2023-05-11T19:05:44.645650Z",
     "shell.execute_reply.started": "2023-05-11T19:05:44.641461Z"
    },
    "id": "55o-kw5F7Mq5",
    "outputId": "cea5b29b-d988-4d74-b4d7-75db6ec260bb"
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models,x_test,y_test):\n",
    "    for model in models:\n",
    "        print(f\"{model['name']}\")\n",
    "        print(f\"Best parameters: {model['model'].best_params_}\")\n",
    "        print(f\"Best CV score: {model['model'].best_score_}\")\n",
    "        y_pred = model['best'].predict(x_test)\n",
    "        evaluate(y_test, y_pred, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tried:\n",
    "- glove-wiki-gigaword-50\n",
    "- word2vec-google-news-300\n",
    "- conceptnet-numberbatch-17-06-300\n",
    "- fasttext-wiki-news-subwords-300\n",
    "- glove-twitter-100\n",
    "- glove-twitter-200\n",
    "- glove-twitter-25\n",
    "- word2vec-ruscorpora-300\n",
    "\n",
    "Best results with word2vec-google-news-300 with around 46 percent accuracy on SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:05:48.270659Z",
     "iopub.status.busy": "2023-05-11T19:05:48.270309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression\n",
      "Fitting 5 folds for each of 17 candidates, totalling 85 fits\n"
     ]
    }
   ],
   "source": [
    "model,x_train, x_test, y_train, y_test=prep_dataset(\"word2vec-google-news-300\",300,True)\n",
    "models=setup_models()\n",
    "train_models(models,x_train,y_train)\n",
    "evaluate_models(models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you need to stop the engine and wait until it stops',\n",
       " 'This is how I would do it: // Check if its safe',\n",
       " 'The Commission shall publish the report; an interim report at least once every two years, and whenever it considers that such a report is necessary or appropriate']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [re.sub('\\n', ' ', doc) for doc in df.text]\n",
    "sentences = [re.split('[?!.]\\s', doc) for doc in docs]\n",
    "sentences = list(flatten(sentences))\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '[' + string.punctuation + ']'\n",
    "\n",
    "def vectorize_embd(docs, embedding_model, useSum=False,dim=50):\n",
    " \n",
    "    vectors = np.zeros((len(docs),dim))\n",
    "    for i in range(len(docs)):\n",
    "        tokens = re.sub(regex, '', docs[i].lower()).split()\n",
    "        embeddings = [embedding_model.wv[token] for token in tokens if token in embedding_model.wv.key_to_index]\n",
    "        \n",
    "        if (len(embeddings) > 0):\n",
    "            if (useSum): \n",
    "                vectors[i] = sum(embeddings)\n",
    "            else:\n",
    "                vectors[i] = np.mean(embeddings, axis=0)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_word(dim):\n",
    "    model = Word2Vec(tokenized_sentences, vector_size=dim, min_count=5, window=10)\n",
    "    x_train = vectorize_embd(np.array(df['text']),model,True,dim)\n",
    "    y_train= np.array(df['label'])\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = split(x_train, y_train, test_size=0.2, val_size=0.0)\n",
    "    return model,x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tried with deifferente dimensions:\n",
    "- 25\n",
    "- 50\n",
    "- 100 \n",
    "- 200 \n",
    "- 300\n",
    "\n",
    "Best results with 200 with around 43 percent accuracy on SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,x_train, x_test, y_train, y_test=prep_dataset_word(200)\n",
    "models=setup_models()\n",
    "train_models(models,x_train,y_train)\n",
    "evaluate_models(models,x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
